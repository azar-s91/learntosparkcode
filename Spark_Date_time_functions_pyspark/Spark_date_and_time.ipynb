{"cells":[{"cell_type":"code","source":["print(\"learntospark.com\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3342c2c8-79e1-4c9a-9453-dbd682c006a9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["displayHTML(\"\"\"\n<center><img src='files/learnspark_img/learn.JPG' width='250' height='250'><img src='files/learnspark_img/spark.png' width='280' height='220'></center>\n<H1><center><B><font color=\"Blue\">www.learntospark.com</font></B></center></H1>\n<H1><center><U>Apache Spark - Tutorial</U><center></H1>\n<H1><center>Spark Functions on Date and Time</center></H1>\n\"\"\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ce98dad-f390-4888-af70-f0a7fa5fbcf7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n\nhttps://issues.apache.org/jira/browse/SPARK-19228"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Some Useful Links for Date Time","showTitle":true,"inputWidgets":{},"nuid":"d7b181b0-0064-4a36-b631-e43f15b870ac"}}},{"cell_type":"code","source":["list_data=[\n           [\"2022/03/31 01:55 AM\"],\n           [\"2022/03/30 01:15 AM\"],\n           [\"2022/03/29 02:15 PM\"],\n           [\"2022/04/01 04:15 PM\"],\n          ]\n\nlist_schema=[\"inp_col\"]\n\n#Create DataFrame from the list \ndf1=spark.createDataFrame(list_data,list_schema)\n\ndf1.printSchema()\n\ndf1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create input DF from list","showTitle":true,"inputWidgets":{},"nuid":"b12f132a-c505-4e00-9ed9-c7c8452e26ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- inp_col: string (nullable = true)\n\n+-------------------+\n|            inp_col|\n+-------------------+\n|2022/03/31 01:55 AM|\n|2022/03/30 01:15 AM|\n|2022/03/29 02:15 PM|\n|2022/04/01 04:15 PM|\n+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- inp_col: string (nullable = true)\n\n+-------------------+\n|            inp_col|\n+-------------------+\n|2022/03/31 01:55 AM|\n|2022/03/30 01:15 AM|\n|2022/03/29 02:15 PM|\n|2022/04/01 04:15 PM|\n+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4caf4dc-036d-428c-ad61-70f6d43fead2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import to_date,date_format,to_timestamp\n\ndf2 = df1.withColumn(\"date\",to_date(\"inp_col\",\"yyyy/MM/dd\")) \\\n         .withColumn(\"time\",to_timestamp(\"inp_col\",\"yyyy/MM/dd hh:mm a\")) \\\n      \n\n\ndf2.printSchema()\ndf2.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Change string to date or timestamp","showTitle":true,"inputWidgets":{},"nuid":"1797b0a3-895f-45b0-abf5-2b8354c81154"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- inp_col: string (nullable = true)\n |-- date: date (nullable = true)\n |-- time: timestamp (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- inp_col: string (nullable = true)\n |-- date: date (nullable = true)\n |-- time: timestamp (nullable = true)\n\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["2022/03/31 01:55 AM","2022-03-31","2022-03-31T01:55:00.000+0000"],["2022/03/30 01:15 AM","2022-03-30","2022-03-30T01:15:00.000+0000"],["2022/03/29 02:15 PM","2022-03-29","2022-03-29T14:15:00.000+0000"],["2022/04/01 04:15 PM","2022-04-01","2022-04-01T16:15:00.000+0000"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"inp_col","type":"\"string\"","metadata":"{}"},{"name":"date","type":"\"date\"","metadata":"{}"},{"name":"time","type":"\"timestamp\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>inp_col</th><th>date</th><th>time</th></tr></thead><tbody><tr><td>2022/03/31 01:55 AM</td><td>2022-03-31</td><td>2022-03-31T01:55:00.000+0000</td></tr><tr><td>2022/03/30 01:15 AM</td><td>2022-03-30</td><td>2022-03-30T01:15:00.000+0000</td></tr><tr><td>2022/03/29 02:15 PM</td><td>2022-03-29</td><td>2022-03-29T14:15:00.000+0000</td></tr><tr><td>2022/04/01 04:15 PM</td><td>2022-04-01</td><td>2022-04-01T16:15:00.000+0000</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Get Year Month Day Hour Min quater WeekofYear"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0558548-1362-48a1-ae2d-163e014bfce5"}}},{"cell_type":"code","source":["from pyspark.sql.functions import year,month,dayofmonth,hour,minute,second,dayofweek,quarter,weekofyear  \n\n# To Get Year from date or Time column\ndf3 = df2.withColumn(\"year\",year(\"time\"))\n\n# To Get Month from date or Time column\ndf3 = df3.withColumn(\"month\",month(\"time\"))\n\n# To Get day from date or Time column\ndf3 = df3.withColumn(\"day\",dayofmonth(\"time\"))\n\n# To Get hour from Time column\ndf3 = df3.withColumn(\"hour\",hour(\"time\"))\n\n# To Get Minute from Time column\ndf3 = df3.withColumn(\"min\",minute(\"time\"))\n\n# To Get Quarter from date or Time column\ndf3 = df3.withColumn(\"quarter-of-year\",quarter(\"time\"))\n\n# To Get week of year from date or Time column\ndf3 = df3.withColumn(\"week-of-year\",weekofyear(\"time\")) \n   \n\ndf3.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afb9e1af-5211-4876-8862-349f267f427a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["2022/03/31 01:55 AM","2022-03-31","2022-03-31T01:55:00.000+0000",2022,3,31,1,55,1,13],["2022/03/30 01:15 AM","2022-03-30","2022-03-30T01:15:00.000+0000",2022,3,30,1,15,1,13],["2022/03/29 02:15 PM","2022-03-29","2022-03-29T14:15:00.000+0000",2022,3,29,14,15,1,13],["2022/04/01 04:15 PM","2022-04-01","2022-04-01T16:15:00.000+0000",2022,4,1,16,15,2,13]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"inp_col","type":"\"string\"","metadata":"{}"},{"name":"date","type":"\"date\"","metadata":"{}"},{"name":"time","type":"\"timestamp\"","metadata":"{}"},{"name":"year","type":"\"integer\"","metadata":"{}"},{"name":"month","type":"\"integer\"","metadata":"{}"},{"name":"day","type":"\"integer\"","metadata":"{}"},{"name":"hour","type":"\"integer\"","metadata":"{}"},{"name":"min","type":"\"integer\"","metadata":"{}"},{"name":"quarter-of-year","type":"\"integer\"","metadata":"{}"},{"name":"week-of-year","type":"\"integer\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>inp_col</th><th>date</th><th>time</th><th>year</th><th>month</th><th>day</th><th>hour</th><th>min</th><th>quarter-of-year</th><th>week-of-year</th></tr></thead><tbody><tr><td>2022/03/31 01:55 AM</td><td>2022-03-31</td><td>2022-03-31T01:55:00.000+0000</td><td>2022</td><td>3</td><td>31</td><td>1</td><td>55</td><td>1</td><td>13</td></tr><tr><td>2022/03/30 01:15 AM</td><td>2022-03-30</td><td>2022-03-30T01:15:00.000+0000</td><td>2022</td><td>3</td><td>30</td><td>1</td><td>15</td><td>1</td><td>13</td></tr><tr><td>2022/03/29 02:15 PM</td><td>2022-03-29</td><td>2022-03-29T14:15:00.000+0000</td><td>2022</td><td>3</td><td>29</td><td>14</td><td>15</td><td>1</td><td>13</td></tr><tr><td>2022/04/01 04:15 PM</td><td>2022-04-01</td><td>2022-04-01T16:15:00.000+0000</td><td>2022</td><td>4</td><td>1</td><td>16</td><td>15</td><td>2</td><td>13</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\nselect weekofyear(\"2020-01-01\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Weekofyear - ISO explanation","showTitle":true,"inputWidgets":{},"nuid":"bd67e30d-9eb0-4b06-8116-afceaccb216c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"weekofyear(2020-01-01)","type":"\"integer\"","metadata":"{\"__autoGeneratedAlias\":\"true\"}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>weekofyear(2020-01-01)</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df3=df2.withColumn(\"dayofweek\",dayofweek(\"time\")) \\\n   .withColumn(\"dayinwords\",date_format(\"time\", \"EEE\")) \\\n   .withColumn(\"monthinwords\",date_format(\"time\", \"LLL\")) \n\ndf3.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Day and Month in Words","showTitle":true,"inputWidgets":{},"nuid":"c2b07363-d436-48a5-9f1e-bc373a053e68"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["2022/03/31 01:55 AM","2022-03-31","2022-03-31T01:55:00.000+0000",5,"Thu","Mar"],["2022/03/30 01:15 AM","2022-03-30","2022-03-30T01:15:00.000+0000",4,"Wed","Mar"],["2022/03/29 02:15 PM","2022-03-29","2022-03-29T14:15:00.000+0000",3,"Tue","Mar"],["2022/04/01 04:15 PM","2022-04-01","2022-04-01T16:15:00.000+0000",6,"Fri","Apr"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"inp_col","type":"\"string\"","metadata":"{}"},{"name":"date","type":"\"date\"","metadata":"{}"},{"name":"time","type":"\"timestamp\"","metadata":"{}"},{"name":"dayofweek","type":"\"integer\"","metadata":"{}"},{"name":"dayinwords","type":"\"string\"","metadata":"{}"},{"name":"monthinwords","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>inp_col</th><th>date</th><th>time</th><th>dayofweek</th><th>dayinwords</th><th>monthinwords</th></tr></thead><tbody><tr><td>2022/03/31 01:55 AM</td><td>2022-03-31</td><td>2022-03-31T01:55:00.000+0000</td><td>5</td><td>Thu</td><td>Mar</td></tr><tr><td>2022/03/30 01:15 AM</td><td>2022-03-30</td><td>2022-03-30T01:15:00.000+0000</td><td>4</td><td>Wed</td><td>Mar</td></tr><tr><td>2022/03/29 02:15 PM</td><td>2022-03-29</td><td>2022-03-29T14:15:00.000+0000</td><td>3</td><td>Tue</td><td>Mar</td></tr><tr><td>2022/04/01 04:15 PM</td><td>2022-04-01</td><td>2022-04-01T16:15:00.000+0000</td><td>6</td><td>Fri</td><td>Apr</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import current_date,datediff,date_add,date_sub,date_trunc\n\n\n#Get Todays date\ndf3=df2.withColumn(\"cur_date\",current_date()) \n\n#Get Date difference\ndf3=df3.withColumn(\"datedif\",datediff(\"date\",\"cur_date\"))\n\n#Add N days to date\ndf3=df3.withColumn(\"dateadd\",date_add(\"date\",5))\n\n#Subtract N days to date\ndf3=df3.withColumn(\"datesub\",date_sub(\"date\",5))\n\n#date truncate\ndf3=df3.withColumn(\"datetrnc\",date_trunc('mm',\"time\"))\n   \ndf3.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc907bc8-057b-4b32-a723-c01735d23bd0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["2022/03/31 01:55 AM","2022-03-31","2022-03-31T01:55:00.000+0000","2022-06-04",-65,"2022-04-05","2022-03-26","2022-03-01T00:00:00.000+0000"],["2022/03/30 01:15 AM","2022-03-30","2022-03-30T01:15:00.000+0000","2022-06-04",-66,"2022-04-04","2022-03-25","2022-03-01T00:00:00.000+0000"],["2022/03/29 02:15 PM","2022-03-29","2022-03-29T14:15:00.000+0000","2022-06-04",-67,"2022-04-03","2022-03-24","2022-03-01T00:00:00.000+0000"],["2022/04/01 04:15 PM","2022-04-01","2022-04-01T16:15:00.000+0000","2022-06-04",-64,"2022-04-06","2022-03-27","2022-04-01T00:00:00.000+0000"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"inp_col","type":"\"string\"","metadata":"{}"},{"name":"date","type":"\"date\"","metadata":"{}"},{"name":"time","type":"\"timestamp\"","metadata":"{}"},{"name":"cur_date","type":"\"date\"","metadata":"{}"},{"name":"datedif","type":"\"integer\"","metadata":"{}"},{"name":"dateadd","type":"\"date\"","metadata":"{}"},{"name":"datesub","type":"\"date\"","metadata":"{}"},{"name":"datetrnc","type":"\"timestamp\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>inp_col</th><th>date</th><th>time</th><th>cur_date</th><th>datedif</th><th>dateadd</th><th>datesub</th><th>datetrnc</th></tr></thead><tbody><tr><td>2022/03/31 01:55 AM</td><td>2022-03-31</td><td>2022-03-31T01:55:00.000+0000</td><td>2022-06-04</td><td>-65</td><td>2022-04-05</td><td>2022-03-26</td><td>2022-03-01T00:00:00.000+0000</td></tr><tr><td>2022/03/30 01:15 AM</td><td>2022-03-30</td><td>2022-03-30T01:15:00.000+0000</td><td>2022-06-04</td><td>-66</td><td>2022-04-04</td><td>2022-03-25</td><td>2022-03-01T00:00:00.000+0000</td></tr><tr><td>2022/03/29 02:15 PM</td><td>2022-03-29</td><td>2022-03-29T14:15:00.000+0000</td><td>2022-06-04</td><td>-67</td><td>2022-04-03</td><td>2022-03-24</td><td>2022-03-01T00:00:00.000+0000</td></tr><tr><td>2022/04/01 04:15 PM</td><td>2022-04-01</td><td>2022-04-01T16:15:00.000+0000</td><td>2022-06-04</td><td>-64</td><td>2022-04-06</td><td>2022-03-27</td><td>2022-04-01T00:00:00.000+0000</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80f861f1-96f7-445d-96a7-47fd50fbd97a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["help(date_add)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84e41da7-0ef6-4bb0-8fda-f9959744383a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Help on function date_add in module pyspark.sql.functions:\n\ndate_add(start, days)\n    Returns the date that is `days` days after `start`\n    \n    .. versionadded:: 1.5.0\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('2015-04-08',)], ['dt'])\n    >>> df.select(date_add(df.dt, 1).alias('next_date')).collect()\n    [Row(next_date=datetime.date(2015, 4, 9))]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function date_add in module pyspark.sql.functions:\n\ndate_add(start, days)\n    Returns the date that is `days` days after `start`\n    \n    .. versionadded:: 1.5.0\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('2015-04-08',)], ['dt'])\n    >>> df.select(date_add(df.dt, 1).alias('next_date')).collect()\n    [Row(next_date=datetime.date(2015, 4, 9))]\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c584f52f-cfab-4359-8b71-62f8d78cefcb"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Spark_date_and_time","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3434667679382180}},"nbformat":4,"nbformat_minor":0}
