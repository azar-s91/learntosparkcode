{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment\n",
    "\n",
    "1. Read the input testfile (Pipe delimited) provided as a \"Spark RDD\" \n",
    "2. Remove the Header Record from the RDD\n",
    "3. Calculate Final_Price:\n",
    "        Final_Price = (Size * Price_SQ_FT)\n",
    "4. Save the final rdd into Textfile with\n",
    "        Property_ID|Location|Final_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession and sparkcontext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName('Assignment 2')\\\n",
    "                    .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the input file as RDD using Spark Context\n",
    "rdd_in=sc.textFile(\"input.txt\")\n",
    "\n",
    "#Apply Filter to get header and data\n",
    "rdd1=rdd_in.filter(lambda l: not l.startswith(\"Property_ID\"))\n",
    "header=rdd_in.filter(lambda l: l.startswith(\"Property_ID\"))\n",
    "\n",
    "#Apply Map and flatMap to get the column data\n",
    "rdd2=rdd1.flatMap(lambda x:x.split(',')).map(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the index of the required column\n",
    "col_list=header.first().split('|')\n",
    "f1=col_list.index(\"Property_ID\")\n",
    "f2=col_list.index(\"Location\")\n",
    "f3=col_list.index(\"Size\")\n",
    "f4=col_list.index(\"Price_SQ_FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definition to calculate the final price\n",
    "def mul_price(d1,d2):\n",
    "    res=float(d1)*float(d2)\n",
    "    return str(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and create final result as expected\n",
    "header_out=header.map(lambda x: x.split(\"|\")[f1]+\"|\"+x.split(\"|\")[f2]+\"|Final_Price\")\n",
    "rdd3=rdd2.map(lambda x: x[f1]+\"|\"+x[f2]+\"|\"+ mul_price(x[f3],x[f4]))\n",
    "\n",
    "final_out=header_out.union(rdd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Property_ID|Location|Final_Price',\n",
       " '1461262|Arroyo Grande|866126.3',\n",
       " '1478004|Paulo Pablo|460996.62',\n",
       " '1486551|Paulo Pablo|545002.0',\n",
       " '1492832|Santa Bay|1015201.2',\n",
       " '1499102|Thomas Country|123638.51']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the final Spark RDD as textfile\n",
    "final_out.coalesce(1).saveAsTextFile(\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
